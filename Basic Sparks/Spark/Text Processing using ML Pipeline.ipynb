{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tmporting relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ML Pipeline').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data\n",
    "data = spark.read.csv('Data/process_yelp.csv', header = True, inferSchema = True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types\n",
    "#Change data type to int\n",
    "data = data.withColumn('stars', data['stars'].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure an ML pipeline\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol='features')\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "\n",
    "#Setting the stages of the ML pipeline\n",
    "pipeline = Pipeline(stages = [tokenizer, hashingTF, lr])\n",
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Predictions\n",
    "prediction = model.transform(data)\n",
    "selected = prediction.select(\"stars\", \"text\", \"Probability\", \"Prediction\")\n",
    "\n",
    "for row in selected.collect():\n",
    "    prob, prediction = row\n",
    "    print(\" (%d, %s) ---> prob = %s, Prediction = %f % (id, text, str(prob), prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d49cb3847ad6cdc01a5ef95effaae1c51d5ce46c335c4cbfbf188202cb823f3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
