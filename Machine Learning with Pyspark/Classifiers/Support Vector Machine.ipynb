{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "###### SVM constructs a hyperplane or set of hyperplanes in a high or infinite-dimensional space, which can be used for classification, regression, or other tasks. Intuitively, a good separation is achieved by the hyperplane that has the largest distance to the nearest training-data points of any class (so-called functional margin),since in gneral the larger the margin the lower the generalization error of the classifier. LinearSVC is spark ML supports binary classification with linear SVM. Internally, it optimizes the Hinge Loss using OWLQN optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----+\n",
      "|Kyphosis|Age|Number|Start|\n",
      "+--------+---+------+-----+\n",
      "|  absent| 71|     3|    5|\n",
      "|  absent|158|     3|   14|\n",
      "| present|128|     4|    5|\n",
      "|  absent|  2|     5|    1|\n",
      "|  absent|  1|     4|   15|\n",
      "|  absent|  1|     2|   16|\n",
      "|  absent| 61|     2|   17|\n",
      "|  absent| 37|     3|   16|\n",
      "|  absent|113|     2|   16|\n",
      "| present| 59|     6|   12|\n",
      "| present| 82|     5|   14|\n",
      "|  absent|148|     3|   16|\n",
      "|  absent| 18|     5|    2|\n",
      "|  absent|  1|     4|   12|\n",
      "|  absent|168|     3|   18|\n",
      "|  absent|  1|     3|   16|\n",
      "|  absent| 78|     6|   15|\n",
      "|  absent|175|     5|   13|\n",
      "|  absent| 80|     5|   16|\n",
      "|  absent| 27|     4|    9|\n",
      "+--------+---+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"SVM\").getOrCreate()\n",
    "training = spark.read.csv(\"..\\Data\\kyphosis.csv\", header = True, inferSchema = True)\n",
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----+------------+\n",
      "|Kyphosis|Age|Number|Start|indexedLabel|\n",
      "+--------+---+------+-----+------------+\n",
      "|  absent| 71|     3|    5|         0.0|\n",
      "|  absent|158|     3|   14|         0.0|\n",
      "| present|128|     4|    5|         1.0|\n",
      "|  absent|  2|     5|    1|         0.0|\n",
      "|  absent|  1|     4|   15|         0.0|\n",
      "|  absent|  1|     2|   16|         0.0|\n",
      "|  absent| 61|     2|   17|         0.0|\n",
      "|  absent| 37|     3|   16|         0.0|\n",
      "|  absent|113|     2|   16|         0.0|\n",
      "| present| 59|     6|   12|         1.0|\n",
      "| present| 82|     5|   14|         1.0|\n",
      "|  absent|148|     3|   16|         0.0|\n",
      "|  absent| 18|     5|    2|         0.0|\n",
      "|  absent|  1|     4|   12|         0.0|\n",
      "|  absent|168|     3|   18|         0.0|\n",
      "|  absent|  1|     3|   16|         0.0|\n",
      "|  absent| 78|     6|   15|         0.0|\n",
      "|  absent|175|     5|   13|         0.0|\n",
      "|  absent| 80|     5|   16|         0.0|\n",
      "|  absent| 27|     4|    9|         0.0|\n",
      "+--------+---+------+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "labelIndexer = StringIndexer(inputCol = \"Kyphosis\", outputCol = \"indexedLabel\").fit(training)\n",
    "trainIndexed = labelIndexer.transform(training)\n",
    "trainIndexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----+------------+----------------+\n",
      "|Kyphosis|Age|Number|Start|indexedLabel|        features|\n",
      "+--------+---+------+-----+------------+----------------+\n",
      "|  absent| 71|     3|    5|         0.0|  [71.0,3.0,5.0]|\n",
      "|  absent|158|     3|   14|         0.0|[158.0,3.0,14.0]|\n",
      "| present|128|     4|    5|         1.0| [128.0,4.0,5.0]|\n",
      "|  absent|  2|     5|    1|         0.0|   [2.0,5.0,1.0]|\n",
      "|  absent|  1|     4|   15|         0.0|  [1.0,4.0,15.0]|\n",
      "|  absent|  1|     2|   16|         0.0|  [1.0,2.0,16.0]|\n",
      "|  absent| 61|     2|   17|         0.0| [61.0,2.0,17.0]|\n",
      "|  absent| 37|     3|   16|         0.0| [37.0,3.0,16.0]|\n",
      "|  absent|113|     2|   16|         0.0|[113.0,2.0,16.0]|\n",
      "| present| 59|     6|   12|         1.0| [59.0,6.0,12.0]|\n",
      "| present| 82|     5|   14|         1.0| [82.0,5.0,14.0]|\n",
      "|  absent|148|     3|   16|         0.0|[148.0,3.0,16.0]|\n",
      "|  absent| 18|     5|    2|         0.0|  [18.0,5.0,2.0]|\n",
      "|  absent|  1|     4|   12|         0.0|  [1.0,4.0,12.0]|\n",
      "|  absent|168|     3|   18|         0.0|[168.0,3.0,18.0]|\n",
      "|  absent|  1|     3|   16|         0.0|  [1.0,3.0,16.0]|\n",
      "|  absent| 78|     6|   15|         0.0| [78.0,6.0,15.0]|\n",
      "|  absent|175|     5|   13|         0.0|[175.0,5.0,13.0]|\n",
      "|  absent| 80|     5|   16|         0.0| [80.0,5.0,16.0]|\n",
      "|  absent| 27|     4|    9|         0.0|  [27.0,4.0,9.0]|\n",
      "+--------+---+------+-----+------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Assemly all Features\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler = VectorAssembler(inputCols = [\"Age\", \"Number\", \"Start\"], outputCol = \"features\")\n",
    "output = featureassembler.transform(trainIndexed)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+\n",
      "|        features|indexedLabel|\n",
      "+----------------+------------+\n",
      "|  [71.0,3.0,5.0]|         0.0|\n",
      "|[158.0,3.0,14.0]|         0.0|\n",
      "| [128.0,4.0,5.0]|         1.0|\n",
      "|   [2.0,5.0,1.0]|         0.0|\n",
      "|  [1.0,4.0,15.0]|         0.0|\n",
      "|  [1.0,2.0,16.0]|         0.0|\n",
      "| [61.0,2.0,17.0]|         0.0|\n",
      "| [37.0,3.0,16.0]|         0.0|\n",
      "|[113.0,2.0,16.0]|         0.0|\n",
      "| [59.0,6.0,12.0]|         1.0|\n",
      "| [82.0,5.0,14.0]|         1.0|\n",
      "|[148.0,3.0,16.0]|         0.0|\n",
      "|  [18.0,5.0,2.0]|         0.0|\n",
      "|  [1.0,4.0,12.0]|         0.0|\n",
      "|[168.0,3.0,18.0]|         0.0|\n",
      "|  [1.0,3.0,16.0]|         0.0|\n",
      "| [78.0,6.0,15.0]|         0.0|\n",
      "|[175.0,5.0,13.0]|         0.0|\n",
      "| [80.0,5.0,16.0]|         0.0|\n",
      "|  [27.0,4.0,9.0]|         0.0|\n",
      "+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data = output.select(\"features\", \"indexedLabel\")\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = finalized_data.randomSplit([0.7, 0.3], 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(featuresCol=\"features\",\n",
    "                 labelCol=\"indexedLabel\", maxIter=10, regParam=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit tht Model \n",
    "lsvcModel = lsvc.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0013192749316592355,0.06863346641500623,-0.030499745618597404]\n",
      "Intercept: -1.1235857645035567\n"
     ]
    }
   ],
   "source": [
    "#Print the Coefficients and intercept\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lsvcModel.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(prediction.accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdul Majeed Ahmed\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------------+----------+\n",
      "|        features|indexedLabel|       rawPrediction|prediction|\n",
      "+----------------+------------+--------------------+----------+\n",
      "|  [2.0,3.0,13.0]|         0.0|[1.31154350843698...|       0.0|\n",
      "| [15.0,5.0,16.0]|         0.0|[1.24862523835119...|       0.0|\n",
      "|  [18.0,5.0,2.0]|         0.0|[0.81767097489585...|       0.0|\n",
      "| [36.0,4.0,13.0]|         0.0|[1.19805469434556...|       0.0|\n",
      "| [37.0,3.0,16.0]|         0.0|[1.35686812268470...|       0.0|\n",
      "| [59.0,6.0,12.0]|         1.0|[0.99994469246879...|       0.0|\n",
      "| [78.0,6.0,15.0]|         0.0|[1.06637770562306...|       0.0|\n",
      "| [105.0,6.0,5.0]|         1.0|[0.72575982628228...|       0.0|\n",
      "| [114.0,7.0,8.0]|         1.0|[0.73675212233813...|       0.0|\n",
      "|[140.0,5.0,11.0]|         0.0|[0.93121714380080...|       0.0|\n",
      "|[158.0,3.0,14.0]|         0.0|[1.13623636471674...|       0.0|\n",
      "|[195.0,2.0,17.0]|         0.0|[1.24755589551614...|       0.0|\n",
      "+----------------+------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9259259259259259"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.areaUnderROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "628797e2199d5443b496a95e8e0b31a4169d065bfd469583647f4ca67435a64c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
